{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import check_output\n",
    "import shlex\n",
    "os.chdir(check_output(shlex.split(\"git rev-parse --show-toplevel\")).strip().decode('ascii'))\n",
    "\n",
    "from CardiacMesh import Cardiac3DMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"1000215\"\n",
    "\n",
    "fhm_mesh = Cardiac3DMesh(\n",
    "    filename=f\"/home/rodrigo/01_repos/CardiacCOMA/data/cardio/meshes/by_id/{ID}/models/FHM_time001.npy\",\n",
    "    faces_filename=\"/home/rodrigo/01_repos/CardioMesh/data/faces_fhm_10pct_decimation.csv\",\n",
    "    subpart_id_filename=\"/home/rodrigo/01_repos/CardioMesh/data/subpartIDs_FHM_10pct.txt\"\n",
    ")\n",
    "\n",
    "lv_subparts = (\"LV\")\n",
    "lv_mesh = fhm_mesh[\"LV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Remove base region from LV mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Compute principal axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of the point cloud\n",
    "point_cloud = lv_mesh.v\n",
    "mean = np.mean(point_cloud, axis=0)\n",
    "\n",
    "# Subtract the mean from the point cloud to center it\n",
    "centered_point_cloud = point_cloud - mean\n",
    "\n",
    "# Compute the covariance matrix\n",
    "covariance_matrix = np.cov(centered_point_cloud, rowvar=False)\n",
    "\n",
    "# Compute the eigenvalues and eigenvectors of the covariance matrix\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# Sort the eigenvalues and eigenvectors in descending order\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# The eigenvectors represent the principal inertia axes\n",
    "principal_axes = eigenvectors\n",
    "### Compute principal inertia axes\n",
    "v_axis = principal_axes[:, 0] #\n",
    "h_axis_1 = principal_axes[:, 1] # aligned with aorta\n",
    "h_axis_2 = principal_axes[:, 2]\n",
    "\n",
    "####################################################################################################\n",
    "# HORTIZONTAL PLANES\n",
    "# Determine the position of the slicing planes along this axis\n",
    "min_pos = np.min(centered_point_cloud.dot(v_axis))\n",
    "max_pos = np.max(centered_point_cloud.dot(v_axis))\n",
    "# slice_thickness = (max_pos - min_pos) / (num_slices-1)\n",
    "fractions = [ -0.01, 0.75, 1.01 ]\n",
    "num_slices = len(fractions) - 1  \n",
    "slice_positions = [ min_pos+fraction*(max_pos-min_pos) for fraction in fractions ]\n",
    "\n",
    "condition_slice = {}\n",
    "for j in range(num_slices):\n",
    "    # Classify points based on which side of the slicing plane they fall\n",
    "    above_plane = centered_point_cloud.dot(v_axis) > slice_positions[j]\n",
    "    below_plane = centered_point_cloud.dot(v_axis) < slice_positions[j+1]\n",
    "    condition_slice[j] = above_plane & below_plane\n",
    "    \n",
    "print(condition_slice[0].sum())\n",
    "print(condition_slice[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.array(range(len(lv_mesh.v)))\n",
    "indices_without_top = set(all_indices[condition_slice[0]])\n",
    "vertex_mapping = { j: i for i, j in enumerate(all_indices[condition_slice[0]]) }\n",
    "vertex_reverse_mapping = { i: j for i, j in enumerate(all_indices[condition_slice[0]]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Create a mesh that keeps only the vertices not belong to the base, and computes a new mesh connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_without_top = copy.deepcopy(lv_mesh)\n",
    "\n",
    "# all_indices = np.array(range(len(lv_without_top.v)))\n",
    "indices_without_top = set(all_indices[condition_slice[0]])\n",
    "\n",
    "keep_face = np.zeros(len(lv_without_top.f)).astype(bool)\n",
    "\n",
    "for i, face in enumerate(lv_without_top.f):\n",
    "    keep_face[i] = all([vert in indices_without_top for vert in face])\n",
    "    \n",
    "lv_without_top.points = lv_without_top.points[condition_slice[0]]\n",
    "lv_without_top.triangles = lv_without_top.triangles[keep_face]\n",
    "\n",
    "for i, triangle in enumerate(lv_without_top.triangles):\n",
    "    \n",
    "    lv_without_top.triangles[i] = [ vertex_mapping[vert] for vert in triangle ]\n",
    "    # print(lv_without_top.triangles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Compute new edges and adjacency matrix, based on the triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "lv_without_top._edges = lv_without_top._edges_from_triangles(lv_without_top.triangles)\n",
    "\n",
    "lv_without_top._adj_matrix = sp.csc_matrix((\n",
    "    np.ones(len(lv_without_top._edges)),\n",
    "    ([x[0] for x in lv_without_top._edges], [x[1] for x in lv_without_top._edges]),\n",
    "))\n",
    "\n",
    "lv_without_top._adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Compute dictionary of neighbors-per-vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_dict = {}\n",
    "all_indices = all_indices = np.array(range(len(lv_without_top.v)))\n",
    "\n",
    "for i, _ in enumerate(lv_without_top.v):\n",
    "    neighbors_dict[i] = all_indices[np.array((lv_without_top.adj_matrix[:,i] > 0).todense()).flatten()]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Find connected components to separate epi from endo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connected_components(graph):\n",
    "    visited = set()\n",
    "    components = []\n",
    "\n",
    "    def dfs(node, component):\n",
    "        visited.add(node)\n",
    "        component.append(node)\n",
    "        for neighbor in graph[node]:\n",
    "            if neighbor not in visited:\n",
    "                dfs(neighbor, component)\n",
    "\n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            component = []\n",
    "            dfs(node, component)\n",
    "            components.append(component)\n",
    "\n",
    "    return components\n",
    "\n",
    "# Usage\n",
    "components = find_connected_components(neighbors_dict)\n",
    "\n",
    "for component in components:\n",
    "    print(len(component))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epi_endo_labels = np.zeros(len(lv_without_top.points))\n",
    "# epi_endo_labels[components[0]] = 100\n",
    "# epi_endo_labels[components[1]] = 200\n",
    "# \n",
    "# import meshio\n",
    "# meshio.write_points_cells(\n",
    "#     \"lv_mesh_with_epi_endo.vtk\",\n",
    "#     lv_without_top.points,\n",
    "#     cells={\"triangle\": np.array(lv_without_top.f)},\n",
    "#     point_data={\"subpartID\": epi_endo_labels},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Map vertices in the subsetted mesh to vertex's ids from the original mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epi = [vertex_reverse_mapping[v] for v in components[0]]\n",
    "endo = [vertex_reverse_mapping[v] for v in components[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_endo_labels = np.zeros(len(lv_mesh.points))\n",
    "epi_endo_labels[epi] = 1\n",
    "epi_endo_labels[endo] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshio.write_points_cells(\n",
    "    \"data/LV_4396_vertices_with_epi_endo.vtk\",\n",
    "    lv_mesh.points,\n",
    "    cells={\"triangle\": np.array(lv_mesh.f)},\n",
    "    point_data={\"subpartID\": epi_endo_labels},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
